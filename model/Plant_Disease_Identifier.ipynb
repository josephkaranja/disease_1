{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1551,"status":"ok","timestamp":1666340205574,"user":{"displayName":"Jose Ngama","userId":"05988438935016135488"},"user_tz":-180},"id":"z1G4O13Gjx0u","outputId":"5adbe161-a013-45e5-bc15-a031f19d5314"},"outputs":[],"source":["!wget https://github.com/nandakishormpai2001/Plant_Disease_Detector/raw/main/model/dataset.zip\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1264,"status":"ok","timestamp":1666340217311,"user":{"displayName":"Jose Ngama","userId":"05988438935016135488"},"user_tz":-180},"id":"8dDcbqrkk0nW","outputId":"e504a34f-ed17-4ac1-c078-aec26ee5a422"},"outputs":[],"source":["!unzip dataset.zip\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6086,"status":"ok","timestamp":1666340782251,"user":{"displayName":"Jose Ngama","userId":"05988438935016135488"},"user_tz":-180},"id":"g0N4VXTCk3Kr","outputId":"8f847f59-9d0e-41c8-dc97-95316456b743"},"outputs":[],"source":["!pip install -r requirements.txt\n"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":4035,"status":"ok","timestamp":1666340792819,"user":{"displayName":"Jose Ngama","userId":"05988438935016135488"},"user_tz":-180},"id":"0xs_1sZFk5Sj"},"outputs":[],"source":["from PIL import Image\n","import torch\n","import torchvision\n","from torchvision.transforms import ToTensor\n","import torchvision.transforms as transforms\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import os\n","import pickle"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":540,"status":"ok","timestamp":1666340801449,"user":{"displayName":"Jose Ngama","userId":"05988438935016135488"},"user_tz":-180},"id":"-kd8x7kdk5dK"},"outputs":[],"source":["class Dataset():\n","    def __init__(self):\n","        self.labels,self.images = self.load_data()\n","\n","    # To load images and labels for dataloader\n","    def load_data(self):\n","        labels={}\n","        images = {}\n","        count = 0\n","        # setting resize dimensions\n","        resize = transforms.Compose([transforms.Resize((256,256))])\n","        main_dir = os.listdir(os.path.join(\"dataset\",\"train\"))\n","        reference = {}\n","        # iterating through categories\n","        for i,dir in enumerate(main_dir):\n","            reference[dir]=i\n","            images_list = os.listdir(os.path.join(\"dataset\",\"train\",dir))\n","            local_cnt = 0\n","            # iterating through images in a category\n","            for img in images_list:\n","                # 500 images from each category\n","                if local_cnt<500:\n","                    labels[count] = i\n","                    img_path = os.path.join(\"dataset\",\"train\",dir,img)\n","                    image = Image.open(img_path)\n","                    image = ToTensor()(image)\n","                    images[count] = resize(image)\n","                    count+=1\n","                    local_cnt+=1\n","                else:\n","                    break\n","\n","        print(reference)\n","        return labels,images\n","      \n","    def __len__(self):\n","        return len(self.labels)\n","    \n","\n","    # To return x,y values in each iteration over dataloader as batches.\n","    def __getitem__(self, idx):\n","        return (\n","            self.images[idx],\n","            self.labels[idx],\n","        )"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":2092,"status":"ok","timestamp":1666340812022,"user":{"displayName":"Jose Ngama","userId":"05988438935016135488"},"user_tz":-180},"id":"faipDpxlk6AV"},"outputs":[],"source":["# Inherit from Dataset class\n","class ValDataset(Dataset):\n","\n","    def load_data(self):\n","          labels={}\n","          images = {}\n","          count = 0\n","          resize = transforms.Compose([transforms.Resize((256,256))])\n","          main_dir = os.listdir(os.path.join(\"dataset\",\"valid\"))\n","          for i,dir in enumerate(main_dir):\n","              print(i,dir)\n","              images_list = os.listdir(os.path.join(\"dataset\",\"valid\",dir))\n","              local_cnt = 0\n","              for img in images_list:\n","                  if(local_cnt<100):\n","                      labels[count] = i\n","                      img_path = os.path.join(\"dataset\",\"valid\",dir,img)\n","                      image = Image.open(img_path)\n","                      image = ToTensor()(image)\n","                      images[count] = resize(image)\n","                      count+=1\n","                      local_cnt+=1\n","                  else:\n","                      break\n","\n","          return labels,images"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":1266,"status":"ok","timestamp":1666340821066,"user":{"displayName":"Jose Ngama","userId":"05988438935016135488"},"user_tz":-180},"id":"pfaV-oyWk6CO"},"outputs":[],"source":["# Model Architecture\n","class Network(nn.Module):\n","    def __init__(self):\n","        super(Network,self).__init__()\n","\n","        # CNNs for rgb images \n","        self.conv1= nn.Conv2d(in_channels=3,out_channels=6,kernel_size=5)\n","        self.conv2= nn.Conv2d(in_channels=6,out_channels=12,kernel_size=5)\n","        self.conv3= nn.Conv2d(in_channels=12,out_channels=24,kernel_size=5)\n","        self.conv4= nn.Conv2d(in_channels=24,out_channels=48,kernel_size=5)\n","        \n","        # Connecting CNN outputs with Fully Connected layers\n","        self.fc1 = nn.Linear(in_features=48*12*12,out_features=240)\n","        self.fc2 = nn.Linear(in_features=240,out_features=120)\n","        self.out = nn.Linear(in_features=120,out_features=17)\n","        \n","        \n","    def forward(self,t):\n","        t = t\n","        \n","        t=self.conv1(t)\n","        t=F.relu(t)\n","        t=F.max_pool2d(t,kernel_size = 2, stride = 2)\n","        \n","        \n","        t=self.conv2(t)\n","        t=F.relu(t)\n","        t=F.max_pool2d(t,kernel_size = 2, stride = 2)\n","\n","        t=self.conv3(t)\n","        t=F.relu(t)\n","        t=F.max_pool2d(t,kernel_size = 2, stride = 2)\n","\n","        t=self.conv4(t)\n","        t=F.relu(t)\n","        t=F.max_pool2d(t,kernel_size = 2, stride = 2)\n","        \n","        t=t.reshape(-1,48*12*12)\n","        t=self.fc1(t)\n","        t=F.relu(t)\n","        \n","        \n","        t=self.fc2(t)\n","        t=F.relu(t)\n","        \n","        t=self.out(t)\n","        \n","        \n","        return t"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":648,"status":"ok","timestamp":1666340831034,"user":{"displayName":"Jose Ngama","userId":"05988438935016135488"},"user_tz":-180},"id":"--t7nENxk6Fw"},"outputs":[],"source":["model = Network()\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3644,"status":"ok","timestamp":1666340836991,"user":{"displayName":"Jose Ngama","userId":"05988438935016135488"},"user_tz":-180},"id":"84gqbKdPlm5h","outputId":"7389f25b-9e0d-4a32-bf0f-709d3fa6c5f3"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'Pepper___Bacterial_spot': 0, 'Cherry___Powdery_mildew': 1, 'Tomato___Target_Spot': 2, 'Tomato___Bacterial_spot': 3, 'Potato___Late_blight': 4, 'Tomato___Early_blight': 5, 'Tomato___healthy': 6, 'Tomato___Leaf_Mold': 7, 'Tomato___Tomato_mosaic_virus': 8, 'Tomato___Septoria_leaf_spot': 9, 'Potato___healthy': 10, 'Tomato___Tomato_Yellow_Leaf_Curl_Virus': 11, 'Cherry___healthy': 12, 'Tomato___Spider_mites Two-spotted_spider_mite': 13, 'Tomato___Late_blight': 14, 'Pepper___healthy': 15, 'Potato___Early_blight': 16}\n"]}],"source":["dataset = Dataset()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1707,"status":"ok","timestamp":1666340846116,"user":{"displayName":"Jose Ngama","userId":"05988438935016135488"},"user_tz":-180},"id":"rvr2at2Ilr5y","outputId":"9bafe0ef-f67e-4dcd-be1b-01b1cf3e9f2a"},"outputs":[],"source":["valdataset = ValDataset()"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":1253,"status":"ok","timestamp":1666340855748,"user":{"displayName":"Jose Ngama","userId":"05988438935016135488"},"user_tz":-180},"id":"KKBAxo_2ltH6"},"outputs":[],"source":["# Function to return number of correct predictions in a batch\n","def get_num_correct(preds,labels):\n","    return preds.argmax(dim=1).eq(labels).sum().item()"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":887,"status":"ok","timestamp":1666340859900,"user":{"displayName":"Jose Ngama","userId":"05988438935016135488"},"user_tz":-180},"id":"PZuhXMSCltTk"},"outputs":[],"source":["def train(dataset,valdataset, model):\n","    model.train()\n","\n","    # dataloader in pytorch to load validation and train dataset\n","    dataloader = torch.utils.data.DataLoader(dataset, batch_size=64,shuffle=True)\n","    valdataloader = torch.utils.data.DataLoader(valdataset, batch_size=32,shuffle=True)\n","\n","    # Defining the loss and optimizer\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=0.001)\n","    num_of_epochs = 20\n","    epochs = []\n","    losses = []\n","    for epoch in range(num_of_epochs):\n","        cnt = 0\n","        tot_loss = 0\n","        tot_correct = 0\n","        for batch, (x, y) in enumerate(dataloader):\n","            # Sets the gradients of all optimized tensors to zero\n","            optimizer.zero_grad()\n","            y_pred = model(x)\n","            # Compute loss (here CrossEntropyLoss)\n","            loss = F.cross_entropy(y_pred,y)\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","        for batch, (x, y) in enumerate(valdataloader):\n","            # Sets the gradients of all optimized tensors to zero\n","            optimizer.zero_grad()\n","            with torch.no_grad():\n","                y_pred = model(x)\n","                # Compute loss (here CrossEntropyLoss)\n","                loss = F.cross_entropy(y_pred,y)\n","\n","            tot_loss+=loss.item()\n","            tot_correct +=get_num_correct(y_pred,y)\n","        epochs.append(epoch)\n","        losses.append(tot_loss)\n","        print(\"Epoch\",epoch,\"total_correct\",tot_correct,\"loss:\",tot_loss)\n","        torch.save(model.state_dict(), \"model002_ep\"+str(epoch+1)+\".pth\")\n","\n","    # Plot a Validation Loss vs Epochs graph \n","    plt.plot(epochs, losses, color='green', linewidth = 3, \n","         marker='o', markerfacecolor='blue', markersize=8) \n","    plt.xlabel('epochs ---->',color='m',fontsize='xx-large' ) \n","    plt.ylabel('loss ------>',color='m',fontsize='xx-large') \n","    axes = plt.gca()        # 'gca' - get current axes\n","    axes.set_facecolor('c') #'c' - cyan\n","    axes.tick_params(axis='y', which='both', colors='tomato')\n","    axes.tick_params(axis='x', which='both', colors='#20ff14')\n","    plt.title(\"Val Loss vs Epoch\",color='m',fontsize='xx-large')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"Q7HPReNKl_Dr"},"outputs":[],"source":["train(dataset,valdataset, model)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"t0IO4XbOmKmR"},"outputs":[],"source":["# Saving labels to label value as a json\n","main_dir = os.listdir(os.path.join(\"minidataset\",\"train\"))\n","reference = {}\n","for i,dir in enumerate(main_dir):\n","    reference[dir]=i\n","with open('labels.json', 'wb') as iw:\n","    pickle.dump(reference, iw)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ozeJk__GmO59"},"outputs":[],"source":["#Save the trained model\n","torch.save(model.state_dict(), \"model.pth\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lcQkcccDmUov"},"outputs":[],"source":["# prediction function to test\n","def predict(img_path):\n","    image = Image.open(img_path)\n","    image = ToTensor()(image)\n","    resize = transforms.Compose([transforms.Resize((256,256))])\n","    y_result = model(resize(image).unsqueeze(0))\n","    result_idx = y_result.argmax(dim=1)\n","    for key,value in reference.items():\n","        if(value==result_idx):\n","            print(key)\n","            break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CG6DQaYUmYmp"},"outputs":[],"source":["predict(\"img_path\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNG1uRcQaEGvZU/mj4Mj8+1","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
